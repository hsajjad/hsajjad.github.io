[{"authors":["admin"],"categories":null,"content":" I am an NLP researcher, consultant and mentor blended with entrepreneurial interests. Currently, I am working as a senior research scientist in Arabic Language Technologies group at Qatar Computing Research Institute, Qatar. I manage applied machine learning team that mainly focuses on interpretation of deep NLP models and machine translation.\nSince you ended up on this page and if you are wondering where to go next, here are a few pointers:\n To know more about the research areas I worked on, check out Research!\nTo see my deep learning and NLP courses, check out Teaching!\nYou can find my resume here.\n If you would like to reach out to me for:\n an interesting problem, drop a line here: hasaan.sajjad+nlp@gmail.com  my courses, drop a line here: hasaan.sajjad+coach@gmail.com  else: hasaan.sajjad+general@gmail.com  Recent News  NeuroX Toolkit on pip: https://pypi.org/project/neurox/ Accepted Papers 2021: 1@TACL, 1@NAACL, 1@ACL findings, 2@ICWSM, 1@IWCS Tutorial @NAACL 2021: Fine-grained Interpretation and Causation Analysis in Deep NLP Models Accepted papers 2020: 2@EMNLP, 2@COLING, 1@ACL, 1@CL, 1@NLE Talk: Exploiting Redundancy in Pre-trained Models for Efficient Transfer Learning at Machine Learning and Data Analytics Symposium, Qatar (Mar. 2021), Facebook, US (Feb 2021) and National Research Council, Canada (Nov. 2020) Talk: Hidden Linguistics in Deep NLP Models. Heinrich-Heine Universität Düsseldorf, Germany Media Coverage: One billion tokens translated. Gulf times, Qatar tribune and several TV/radio channels such as Qatar radio and Qatar TV Released: First-ever Dialectal Arabic to English Machine Translation System covering a large variety of Arabic dialects Tech Transfer: Machine Translation Technology to KanariAI Talk: Interpreting Deep NLP Models, University of Edinburgh, UK (April 2020) Talk: University of Sheffield, UK (Mar 2020) Invited talk: Efficient Transfer Learning of Pretrained Model. 7th International Conference on Language and Technology, Pakistan (February 2020) Talk: Analyzing Individual Neurons in Deep NLP Models at Google, Facebook, Amazon, Salesforce and Bosch, US (April 2019) Keynote: Hidden Linguistic in Deep NLP Models, Symposium on Natural Language Processing, University of Moratuwa, Sri Lanka (March 2019)   See all previous news here: News   ","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"//localhost:54935/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am an NLP researcher, consultant and mentor blended with entrepreneurial interests. Currently, I am working as a senior research scientist in Arabic Language Technologies group at Qatar Computing Research Institute, Qatar. I manage applied machine learning team that mainly focuses on interpretation of deep NLP models and machine translation.\nSince you ended up on this page and if you are wondering where to go next, here are a few pointers:","tags":null,"title":"Hassan Sajjad","type":"authors"},{"authors":null,"categories":null,"content":" NeuroX Toolkit on pip: https://pypi.org/project/neurox/ Tutorial @NAACL 2021: Fine-grained Interpretation and Causation Analysis in Deep NLP Models Accepted Papers 2021: 1 TACL, 1 NAACL, 1 ACL findings, 2 ICWSM, 1 IWCS Talk: Exploiting Redundancy in Pre-trained Models for Efficient Transfer Learning. Facebook (Feb. 2021), Machine Learning and Data Analytics Symposium (Mar. 2021), National Research Council, Canada Talk: Hidden Linguistics in Deep NLP Models. Heinrich-Heine Universität Düsseldorf, Germany Accepted @COLING 2020: Two long papers, 1) Dialect Arabic machine translation, 2) Location mention recognition Accepted @EMNLP 2020: Two long papers on interpretabiliy are accepted. Details coming soon! Media Coverage: One billion tokens translated. Gulf times, Qatar tribune and several TV/radio channels such as Qatar radio and Qatar TV Released: First-ever Dialectal Arabic to English Machine Translation System covering a large variety of Arabic dialects Tech Transfer: Machine Translation Technology to KanariAI Accepted @ACL 2020: Similarity Analysis of Contextual Word Representation Models Talk: Interpreting Deep NLP Models, University of Edinburgh, UK (April 2020) Talk: University of Sheffield, UK (Mar 2020) Invited talk: Efficient Transfer Learning of Pretrained Model. 7th International Conference on Language and Technology, Pakistan (February 2020) Talk: Analyzing Individual Neurons in Deep NLP Models at Google, Facebook, Amazon, Salesforce and Bosch, US (April 2019) Keynote: Hidden Linguistic in Deep NLP Models, Symposium on Natural Language Processing, University of Moratuwa, Sri Lanka (March 2019) Deep learning for NLP: Fun teaching at International Spring School in Advanced Language Engineering, University of Moratuwa (March 2019) Talk: Machine Translation in Real World, King\u0026rsquo;s College London, UK (March 2019) Talk: Analyzing Individual Neurons in Deep NLP Models, University of Melbourne, Australia (February 2019) Accepted @NAACL 2019: \u0026ldquo;One Size Does Not Fit All: Comparing NMT Representations of Different Granularities\u0026rdquo; Accepted @NAACL 2019: \u0026ldquo;Highly Effective Arabic Diacritization using Sequence to Sequence Modeling\u0026rdquo; Media coverage: Our work on NeuroX - Analyzing and Controlling Individual Neurons is featured at MIT news and several AI blogs. Accepted @ICLR 2019: \u0026ldquo;Identifying and Controlling Important Neurons in Neural Machine Translation\u0026rdquo; Accepted @AAAI 2019: \u0026ldquo;What Is One Grain of Sand in the Desert? Analyzing Individual Neurons in Deep NLP Models\u0026rdquo; Accepted @AAAI 2019: \u0026ldquo;NeuroX: A toolkit for Analyzing Individual Neurons in Neural Network\u0026rdquo; Best Innovation Award @ARC\u0026rsquo;18 for our Speech Translation System, see media coverage Deep learning for NLP: I will be delivering an intensive course on deep learning for NLP at the University of Duisburg-Essen, Germany in the second week of April 2018 Accepted @NAACL 2018: Incremental decoding and training methods for simultaneous translation in neural machine translation Media coverage: Our work on understanding Neural Machine Translation has made it to MIT news and been picked by several channels like ScienceBlog, ScienceDaily Accepted @IWSLT 2017: Neural Machine Translation Training in a Multi-domain Scenario Deep learning for MT: I had great fun in teaching deep learning for machine translation at the DGfS-CL Fall School. Course material is available here. Accepted two papers @ACL 2017 Read my post about What does Neural Machine Translation Learn about Morphology  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1e779953d2612a9686f31113b9abf4ec","permalink":"//localhost:54935/pages/news/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/pages/news/","section":"pages","summary":"NeuroX Toolkit on pip: https://pypi.org/project/neurox/ Tutorial @NAACL 2021: Fine-grained Interpretation and Causation Analysis in Deep NLP Models Accepted Papers 2021: 1 TACL, 1 NAACL, 1 ACL findings, 2 ICWSM, 1 IWCS Talk: Exploiting Redundancy in Pre-trained Models for Efficient Transfer Learning. Facebook (Feb. 2021), Machine Learning and Data Analytics Symposium (Mar. 2021), National Research Council, Canada Talk: Hidden Linguistics in Deep NLP Models. Heinrich-Heine Universität Düsseldorf, Germany Accepted @COLING 2020: Two long papers, 1) Dialect Arabic machine translation, 2) Location mention recognition Accepted @EMNLP 2020: Two long papers on interpretabiliy are accepted.","tags":null,"title":"News","type":"pages"},{"authors":["Nadir Durrani","Hassan Sajjad","Fahim Dalvi"],"categories":null,"content":"","date":1627765200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627765200,"objectID":"28a351cfb8dc1f28f1206c7c0a056f6d","permalink":"//localhost:54935/publication/durrani-finetuning-acl-2021/","publishdate":"2021-08-01T00:00:00+03:00","relpermalink":"/publication/durrani-finetuning-acl-2021/","section":"publication","summary":"","tags":null,"title":"How transfer learning impacts linguistic knowledge in deep NLP models?","type":"publication"},{"authors":["Firoj Alam","Hassan Sajjad","Muhammad Imran","Ferda Ofli"],"categories":null,"content":"","date":1622494800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622494800,"objectID":"f3de1cd84af995329b35cac504b05509","permalink":"//localhost:54935/publication/crisis-benchmarking-icwsm-21/","publishdate":"2021-06-01T00:00:00+03:00","relpermalink":"/publication/crisis-benchmarking-icwsm-21/","section":"publication","summary":"","tags":null,"title":"CrisisBench: Benchmarking Crisis-related Social Media Datasets for Humanitarian Information Processing","type":"publication"},{"authors":["Firoj Alam","Fahim Dalvi","Shaden Shaar","Nadir Durrani","Hamdy Mubarak","Alex Nikolov","Giovanni Da San Martino","Ahmed Abdelali","Hassan Sajjad","Kareem Darwish","Preslav Nakov"],"categories":null,"content":"","date":1622494800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622494800,"objectID":"a3eb5f95f9fbbc4381be4609cf24e827","permalink":"//localhost:54935/publication/firoj-covid-icwsm-21/","publishdate":"2021-06-01T00:00:00+03:00","relpermalink":"/publication/firoj-covid-icwsm-21/","section":"publication","summary":"","tags":null,"title":"Fighting the COVID-19 Infodemic in Social Media: A Holistic Perspective and a Call to Arms","type":"publication"},{"authors":["Hassan Sajjad","Narine Kokhlikyan","Fahim Dalvi","Nadir Durrani"],"categories":null,"content":"","date":1622494800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622494800,"objectID":"602fa9520ec67fd0785f2c26edc94b86","permalink":"//localhost:54935/publication/sajjad-tutorial-naacl-2021/","publishdate":"2021-06-01T00:00:00+03:00","relpermalink":"/publication/sajjad-tutorial-naacl-2021/","section":"publication","summary":"","tags":null,"title":"Fine-grained Interpretationand Causation Analysis in Deep NLP Models","type":"publication"},{"authors":["Esther Seyffarth","Younes Samih","Laura Kallmeyer","Hassan Sajjad"],"categories":null,"content":"","date":1622494800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622494800,"objectID":"03874032a2c502fe96a76bd6c1dec19d","permalink":"//localhost:54935/publication/esther-causativity-iwcs-21/","publishdate":"2021-06-01T00:00:00+03:00","relpermalink":"/publication/esther-causativity-iwcs-21/","section":"publication","summary":"","tags":null,"title":"Implicit Representations of Event Properties within Contextual Language Models:Searching for ``Causativity Neurons\"","type":"publication"},{"authors":["Prakhar Ganesh","Yao Chen","Xin Lou","Mohammad Ali Khan","Yin Yang","Deming Chen","Marianne Winslett","Hassan Sajjad","Preslav Nakov"],"categories":null,"content":"","date":1609448400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609448400,"objectID":"b6a1931738e782f4ac647ef404bfbcfe","permalink":"//localhost:54935/publication/bert-survey-tacl-20/","publishdate":"2021-01-01T00:00:00+03:00","relpermalink":"/publication/bert-survey-tacl-20/","section":"publication","summary":"","tags":null,"title":"Compressing Large-Scale Transformer-Based Models: A Case Study on BERT","type":"publication"},{"authors":["Hassan Sajjad","Ahmed Abdelali","Nadir Durrani","Fahim Dalvi"],"categories":null,"content":"","date":1606770000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606770000,"objectID":"100fa22a2c23d7e12cfa50d925863e6a","permalink":"//localhost:54935/publication/sajjad-etal-2020-arabench/","publishdate":"2020-12-01T00:00:00+03:00","relpermalink":"/publication/sajjad-etal-2020-arabench/","section":"publication","summary":"","tags":null,"title":"AraBench: Benchmarking Dialectal Arabic-English Machine Translation","type":"publication"},{"authors":["Reem Suwaileh","Muhammad Imran","Tamer Elsayed","Hassan Sajjad"],"categories":null,"content":"","date":1606770000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606770000,"objectID":"58f0ef6fb98273fde9c159279a54f08b","permalink":"//localhost:54935/publication/suwaileh-etal-2020-ready/","publishdate":"2020-12-01T00:00:00+03:00","relpermalink":"/publication/suwaileh-etal-2020-ready/","section":"publication","summary":"","tags":null,"title":"Are We Ready for this Disaster? Towards Location Mention Recognition from Crisis Tweets","type":"publication"},{"authors":["Nadir Durrani","Hassan Sajjad","Fahim Dalvi","Yonatan Belinkov"],"categories":null,"content":"","date":1604178000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604178000,"objectID":"5e437155a48d75371f893f06e54ea489","permalink":"//localhost:54935/publication/durrani-individual-emnlp-20/","publishdate":"2020-11-01T00:00:00+03:00","relpermalink":"/publication/durrani-individual-emnlp-20/","section":"publication","summary":"","tags":null,"title":"Analyzing Individual Neurons in Pre-trained Language Models","type":"publication"},{"authors":["Fahim Dalvi","Hassan Sajjad","Nadir Durrani","Yonatan Belinkov"],"categories":null,"content":"","date":1604178000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604178000,"objectID":"038c8e7e137e24fb014ea33f4789f51d","permalink":"//localhost:54935/publication/dalvi-featureselection-emnlp-20/","publishdate":"2020-11-01T00:00:00+03:00","relpermalink":"/publication/dalvi-featureselection-emnlp-20/","section":"publication","summary":"","tags":null,"title":"Analyzing Redundancy in Pretrained Transformer Models","type":"publication"},{"authors":["Zhenhai Li, Juan Pino, Vishrav Chudhary, Francisco Guzman, Paul Michel, Graham Neubig, Hassan Sajjad, Nadir Durrani, Yonatan Belinkov, Philipp Koehn, Xian Li Lucia Specia"],"categories":null,"content":"","date":1604178000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604178000,"objectID":"cbf8b262b0d580e110ccac5365268f7e","permalink":"//localhost:54935/publication/mtrobustness-2020/","publishdate":"2020-11-01T00:00:00+03:00","relpermalink":"/publication/mtrobustness-2020/","section":"publication","summary":"","tags":null,"title":"Findings of the WMT 2020 Shared Task on Machine Translation Robustness.","type":"publication"},{"authors":["John M. Wu","Yonatan Belinkov","Hassan Sajjad","Nadir Durrani","Fahim Dalvi","James Glass"],"categories":null,"content":"","date":1593896400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593896400,"objectID":"62f2ccb48955c05aac2ab5348356188b","permalink":"//localhost:54935/publication/wu-similarity-acl-20/","publishdate":"2020-07-05T00:00:00+03:00","relpermalink":"/publication/wu-similarity-acl-20/","section":"publication","summary":"","tags":null,"title":"Similarity Analysis of Contextual Word Representation Models","type":"publication"},{"authors":null,"categories":null,"content":" Lecturers: Hassan Sajjad and Fahim Dalvi\n In this lecture series, we first cover the basics of statistical machine translation to establish the intuition behind machine translation. We then cover the basics of neural network models - word embedding and neural language model. Finally, we learn an end-to-end translation system based completely on deep neural networks. In the last part of the lecture series, we learn to peek into these neural systems and analyze what they learn about the intricacies of a language like morphology and syntax, without ever explicitly seeing these details in the training data.\nBackground reading * Python Numpy Tutorial * IPython Tutorial * Linear Aljebra for Machine Learning\nSlides\n Lecture 0 - Introduction \u0026amp; Roadmap slides Lecture 1 - Language \u0026amp; Translation slides Lecture 2 - Language Modeling slides\n Python tutorial Python tutorial as a PDF [non-editable]  Lecture 3 - Machine Learning slides\n Decision Boundary Exercise [iPython/Jupyter Notebook] Optimization functions demonstration [iPython/Jupyter Notebook]  Lecture 4 - Machine Learning II slides\n Linear Classifier with MSE [iPython/Jupyter Notebook] Linear Classifier with Softmax and Cross Entropy [iPython/Jupyter Notebook]  Lecture 5 - Machine Learning and Neural Networks slides\n Efficient Linear Classifier with Softmax and Cross Entropy [iPython/Jupyter Notebook] Neural Network [iPython/Jupyter Notebook] Neural Network with Keras toolkit [iPython/Jupyter Notebook]  Lecture 6 - Neural Network Language Models slides\n Language Modeling with Keras [iPython/Jupyter Notebook]  Lecture 7 - Sequence to Sequence slides\n Lecture 8 - Practical Neural MT slides\n Lecture 9 - Analysis of Neural MT slides\n Lecture 10 - Recent Advancements slides\n  ","date":1593302400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593302400,"objectID":"ab7adecb7f8a51a8e281094e7f5f8e02","permalink":"//localhost:54935/pages/dl4mt/","publishdate":"2020-06-28T00:00:00Z","relpermalink":"/pages/dl4mt/","section":"pages","summary":"Lecturers: Hassan Sajjad and Fahim Dalvi\n In this lecture series, we first cover the basics of statistical machine translation to establish the intuition behind machine translation. We then cover the basics of neural network models - word embedding and neural language model. Finally, we learn an end-to-end translation system based completely on deep neural networks. In the last part of the lecture series, we learn to peek into these neural systems and analyze what they learn about the intricacies of a language like morphology and syntax, without ever explicitly seeing these details in the training data.","tags":null,"title":"Deep Learning for Machine Translation","type":"pages"},{"authors":null,"categories":null,"content":" Lecturers: Fahim Dalvi and Hassan Sajjad\n In this lecture series, we cover the basics of machine learning, neural networks and deep neural networks. We look at several deep neural network architectures from the perspective of applying them to various classification tasks, such as sequence prediction and generation. Every lecture is accompanied with practice problems implemented in Keras, a popular Python framework for deep learning.\nBackground reading * Python Numpy Tutorial * IPython Tutorial * Linear Aljebra for Machine Learning\nSlides\n Lecture 0 - Introduction \u0026amp; Roadmap slides Lecture 1 - Introduction to Machine Learning slides  Practical session slides Learning Rate and Optimization Demo JupyterNotebook Introduction to Jupyter Notebooks JupyterNotebook Introduction to Python and Numpy JupyterNotebook Linear Classification by Regression JupyterNotebook Binary Linear Classification JupyterNotebook Linear Classification on Spiral Data JupyterNotebook Supplementary Material slides  Lecture 2 - Neural Networks slides  Practical session slides Neural Networks on Spiral Data JupyterNotebook Data .zip Sentiment Classification using Neural Networks JupyterNotebook Neural Network Language Model JupyterNotebook  Lecture 3 - Recurrent Neural Networks slides  Practical Session JupyterNotebook Recurrent Neural Networks JupyterNotebook Hybrid Model JupyterNotebook  Lecture 4 - Sequence to Sequence Models and Practical Considerations  Sequence to Sequence Models slides Practical Considerations slides  Per Timestep Prediction JupyterNotebook Pretrained Embeddings JupyterNotebook Imbalanced Classes JupyterNotebook  Lecture 5 - Advanced Topics, CNN, Multitask, GAN, RL, etc. slides  ","date":1593302400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593302400,"objectID":"d8be7aab72fc8828b2285976dff8a976","permalink":"//localhost:54935/pages/dl4nlp/","publishdate":"2020-06-28T00:00:00Z","relpermalink":"/pages/dl4nlp/","section":"pages","summary":"Lecturers: Fahim Dalvi and Hassan Sajjad\n In this lecture series, we cover the basics of machine learning, neural networks and deep neural networks. We look at several deep neural network architectures from the perspective of applying them to various classification tasks, such as sequence prediction and generation. Every lecture is accompanied with practice problems implemented in Keras, a popular Python framework for deep learning.\nBackground reading * Python Numpy Tutorial * IPython Tutorial * Linear Aljebra for Machine Learning","tags":null,"title":"Deep Learning for Natural Language Processing","type":"pages"},{"authors":null,"categories":null,"content":" Highlights  Media coverage: Our work on NeuroX - Analyzing and Controlling Individual Neurons is featured at MIT news and several AI blogs.\nMedia coverage: Our work on understanding Neural Machine Translation has made it to MIT news and been picked by several channels like ScienceBlog, ScienceDaily\n I am interested in understanding the learning dynamics of deep neural network models. I have worked on analyzing whole vector representations and individual neurons in the network and answer questions such as:\n How much linguistic knowledge is learned? How focused and distributed is the information? What is the role of individual neurons?  I showed that the interpretation analysis enables us to:\n control bias in our models by manipulating individual neurons reduce the model size and speed up inference time by removing irrelevant and redundant neurons improve model performance by injecting linguistic information in a multitask setting  The interpretation work is mainly done in collaboration with CSAIL MIT. The work has been published at prestigious venues, such as ICLR, AAAI, ACL, etc., and it has been covered by several technology blogs a couple of times.\n","date":1593302400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593302400,"objectID":"6e758970ac121cffe336ac0db32c7efb","permalink":"//localhost:54935/pages/interpretation/","publishdate":"2020-06-28T00:00:00Z","relpermalink":"/pages/interpretation/","section":"pages","summary":"Highlights  Media coverage: Our work on NeuroX - Analyzing and Controlling Individual Neurons is featured at MIT news and several AI blogs.\nMedia coverage: Our work on understanding Neural Machine Translation has made it to MIT news and been picked by several channels like ScienceBlog, ScienceDaily\n I am interested in understanding the learning dynamics of deep neural network models. I have worked on analyzing whole vector representations and individual neurons in the network and answer questions such as:","tags":null,"title":"Interpretation of Deep NLP Models","type":"pages"},{"authors":null,"categories":null,"content":" Highlights  Live Speech Translation System\nMachine Translation System\nFirst industry scale dialectal Arabic to English machine translation system\nMachine Translation licensed to KanariAI\nLive Speech Translation won the best Innovation award at @ARC\u0026rsquo;18, see media coverage\n I have worked on both statistical and neural machine translation, involving several language pairs such as English, German, Russian, Arabic, Hebrew, etc. I have been interested in improving the translation of resource-poor languages and morphologically-rich languages. Additionally, I worked on domain adaptation and the handling of unknown words. My research work has been published in top tier venues such as ACL, NAACL, EMNLP, etc.\nIn addition to research, I have expertise in building industry-grade and customized machine translation systems. As of July 2020, our system has translated 950 million tokens. The system has been used by Aljazeera, BBC, and DW, and is deployed as part of the H2020 SUMMA project.\n","date":1593302400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593302400,"objectID":"dbf0d650ba7adde907e053359dbc2e18","permalink":"//localhost:54935/pages/mt/","publishdate":"2020-06-28T00:00:00Z","relpermalink":"/pages/mt/","section":"pages","summary":"Highlights  Live Speech Translation System\nMachine Translation System\nFirst industry scale dialectal Arabic to English machine translation system\nMachine Translation licensed to KanariAI\nLive Speech Translation won the best Innovation award at @ARC\u0026rsquo;18, see media coverage\n I have worked on both statistical and neural machine translation, involving several language pairs such as English, German, Russian, Arabic, Hebrew, etc. I have been interested in improving the translation of resource-poor languages and morphologically-rich languages.","tags":null,"title":"Machine Translation","type":"pages"},{"authors":null,"categories":null,"content":"My name is Hassan Sajjad. I am an NLP researcher, consultant and coach blended with entrepreneurial interests.\nCurrently, I am working as a research scientist in Arabic Language Technologies group at Qatar Computing Research Institute, Qatar. I manage applied machine learning team that mainly work on interpretation of deep NLP models, machine translation and transfer learning.\nFollowing is a summary of my areas of interest:\n Research Interests  Applied deep learning and machine learning, unsupervised and semi-supervised learning methods, interpretability and manipulation of neural models, multi-task learning, transfer learning Natural language processing, statistical and neural machine translation, transliteration, domain adaptation, NLP for resource poor languages, and user-generated content processing and analysis  Application Interests  Building large scale practical systems, issues related to deployment of models, problem solving from the perspective of end user, machine translation competitions  Coaching Interests  Deep learning from scratch, explanation of models by developing intuition from real world examples, making understanding theory easy with animations, practical insight of deep learning models  Entrepreneurial Interests  Lean startup, technology transfer, business development, customer validation   Coming back to my bio, other than research work at QCRI I manage applied machine learning group at QCRI, lead deployment and commercialization efforts of QCRI\u0026rsquo;s machine translation technology, managed Arabic machine translation part of the European Project on media monitoring, SUMMA and the collaboration with MIT.\nBefore coming to QCRI, I graduated from University of Stuttgart in Fall 2012 under the supervision of Prof. Dr. Hinrich Schütze. There I closely worked with Alex Fraser, Helmut Schmid and Nadir Durrani. In my PhD, I worked on part-of-speech tagging, statistical machine translation, and unsupervised models for transliteration mining. I also worked at Microsoft Research as an intern where I worked on query expansion for natural language question generation. Before starting PhD, I did bachelors and masters in Computer Science from National University of Computer and Emerging Sciences, Pakistan. In my master thesis, I worked on Part of Speech tagging of Urdu language under the supervision of Dr. Sarmad Hussain.\n","date":1593302400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593302400,"objectID":"310b2326f527c8c36fb9c118ffa50025","permalink":"//localhost:54935/pages/bio/","publishdate":"2020-06-28T00:00:00Z","relpermalink":"/pages/bio/","section":"pages","summary":"My name is Hassan Sajjad. I am an NLP researcher, consultant and coach blended with entrepreneurial interests.\nCurrently, I am working as a research scientist in Arabic Language Technologies group at Qatar Computing Research Institute, Qatar. I manage applied machine learning team that mainly work on interpretation of deep NLP models, machine translation and transfer learning.\nFollowing is a summary of my areas of interest:\n Research Interests  Applied deep learning and machine learning, unsupervised and semi-supervised learning methods, interpretability and manipulation of neural models, multi-task learning, transfer learning Natural language processing, statistical and neural machine translation, transliteration, domain adaptation, NLP for resource poor languages, and user-generated content processing and analysis  Application Interests  Building large scale practical systems, issues related to deployment of models, problem solving from the perspective of end user, machine translation competitions  Coaching Interests  Deep learning from scratch, explanation of models by developing intuition from real world examples, making understanding theory easy with animations, practical insight of deep learning models  Entrepreneurial Interests  Lean startup, technology transfer, business development, customer validation   Coming back to my bio, other than research work at QCRI I manage applied machine learning group at QCRI, lead deployment and commercialization efforts of QCRI\u0026rsquo;s machine translation technology, managed Arabic machine translation part of the European Project on media monitoring, SUMMA and the collaboration with MIT.","tags":null,"title":"Research","type":"pages"},{"authors":null,"categories":null,"content":" I worked on several NLP problems in general. However, the two dominating areas where I worked the most are; machine translation and interpretation of deep NLP models. I have summarized them here: Machine Translation and Interpretation. Later, I summarized my research interests.\nInterpretation Highlights  Media coverage: Our work on NeuroX - Analyzing and Controlling Individual Neurons is featured at MIT news and several AI blogs.\nMedia coverage: Our work on understanding Neural Machine Translation has made it to MIT news and been picked by several channels like ScienceBlog, ScienceDaily\n I am interested in interpreting and understanding the learning dynamics of deep neural network models. I have worked on analyzing whole vector representations and individual neurons in the network and answer questions such as:\n How much linguistic knowledge is learned? How focused and distributed is the information? What is the role of individual neurons?  I showed that the interpretation analysis enables us to:\n control bias in our models by manipulating individual neurons reduce the model size and speed up inference time by removing irrelevant and redundant neurons improve model performance by injecting linguistic information in a multitask setting  The interpretation work is mainly done in collaboration with CSAIL MIT. The work has been published at prestigious venues, such as ICLR, AAAI, ACL, etc., and it has been covered by several technology blogs a couple of times.\nBack to top\nMachine Translation Highlights  Live Speech Translation System\nMachine Translation System\nFirst industry scale dialectal Arabic to English machine translation system\nMachine Translation licensed to KanariAI\nLive Speech Translation won the best Innovation award at @ARC\u0026rsquo;18, see media coverage\n I have worked on both statistical and neural machine translation, involving several language pairs such as English, German, Russian, Arabic, Hebrew, etc. I have been interested in improving the translation of resource-poor languages and morphologically-rich languages. Additionally, I worked on domain adaptation and the handling of unknown words. My research work has been published in top tier venues such as ACL, NAACL, EMNLP, etc.\nIn addition to research, I have expertise in building industry-grade and customized machine translation systems. As of July 2020, our system has translated 950 million tokens. The system has been used by Aljazeera, BBC, and DW, and is deployed as part of the H2020 SUMMA project.\nBack to top\nResearch Interests In the following, I provide a non-exhaustive summary of my areas of interest:\n Research Interests  Applied deep learning and machine learning, unsupervised and semi-supervised learning methods, interpretability and manipulation of neural models, generalization, multi-task learning, transfer learning, representation learning, efficient modeling Natural language processing, statistical and neural machine translation, transliteration, domain adaptation, NLP for resource poor languages, and social media content processing and analysis  Application Interests  Building large scale practical systems, issues related to deployment of models, problem solving from the perspective of end user, machine translation competitions  Coaching Interests  Deep learning from scratch, explanation of models by developing intuition from real world examples, making understanding theory easy with animations, practical insight of deep learning models  Entrepreneurial Interests  Lean startup, technology transfer, business development, customer validation   Back to top\n","date":1593302400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593302400,"objectID":"39c570f6ca8d03881b35b7f0e0a215fa","permalink":"//localhost:54935/pages/research/","publishdate":"2020-06-28T00:00:00Z","relpermalink":"/pages/research/","section":"pages","summary":"I worked on several NLP problems in general. However, the two dominating areas where I worked the most are; machine translation and interpretation of deep NLP models. I have summarized them here: Machine Translation and Interpretation. Later, I summarized my research interests.\nInterpretation Highlights  Media coverage: Our work on NeuroX - Analyzing and Controlling Individual Neurons is featured at MIT news and several AI blogs.\nMedia coverage: Our work on understanding Neural Machine Translation has made it to MIT news and been picked by several channels like ScienceBlog, ScienceDaily","tags":null,"title":"Research","type":"pages"},{"authors":null,"categories":null,"content":" Exploiting Redundancy in Pre-trained Models for Efficient Transfer Learning, Machine Learning and Data Analytics Symposium, Qatar (Mar. 2021) Exploiting Redundancy in Pre-trained Models for Efficient Transfer Learning, Facebook, US (Feb 2021) Exploiting Redundancy in Pre-trained Models for Efficient Transfer Learning, National Research Council, Canada (Nov 2020) Interpreting Deep NLP Models, University of Edinburgh, UK (April 2020) Summarizing Research on Interpreting Machine Translation Models, University of Sheffield, UK (Mar 2020) Efficient Transfer Learning of Pretrained Model, 7th International Conference on Language and Technology, Pakistan (February 2020) Analyzing Individual Neurons in Deep NLP Models at Google, Facebook, Amazon, Salesforce and Bosch, US (April 2019) Hidden Linguistics in Deep NLP Models, Symposium on Natural Language Processing, University of Moratuwa, Sri Lanka (March 2019) Machine Translation in the Real World, Kings College London, UK (March 2019) Analyzing Individual Neurons in Deep NLP Models, University of Melbourne, Melbourne, Australia (Feb. 2019) Analyzing Individual Neurons in Deep NLP Models, Thomson Reuters, Toronto, Canada (Feb. 2019) Research Findings, NRC, Ottawa, Canada (Feb. 2018) What do Neural Machine Translation Models Learn about Morphology, Macquarie University, Sydney, Australia (Apr. 2017) What do Neural Machine Translation Models Learn about Morphology, University of Melbourne, Melbourne, Australia (Apr. 2017) From Phrase-based to Neural Machine Translation. Workshop on Semitic Machine Translation, AMTA, Austin, US (Nov. 2016) (Keynote) Deep Learning – Neural Machine Translation. Sixth Conference on Language and Technology (CLT16), Lahore, Pakistan (Nov. 2016) (Keynote) Content Model Applications for Promoting Local Language Content. Workshop on Facilitating Local Language Content Access and Generation using Human Language Technologies, UET, Lahore, Pakistan (Aug. 2015) (Keynote) Statistical Machine Translation for Community Service: Translating Educational Content. Fifth Conference on Language and Technology (CLT14), Karachi, Pakistan (Nov. 2014) (Keynote) Separating Transliterations from Translations in Transliteration Mining Context. FBK, Trento, Italy (Oct. 2012) Unsupervised Transliteration Mining. School of Science and Engineering, Lahore University of Management and Sciences, Pakistan (Apr. 2012) Unsupervised Transliteration Mining, Punjab University College of Information Technology, Pak- istan (Apr. 2012)  \n","date":1593302400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593302400,"objectID":"e983a5d84d5560bb87f27f185f6ca7c4","permalink":"//localhost:54935/pages/talks/","publishdate":"2020-06-28T00:00:00Z","relpermalink":"/pages/talks/","section":"pages","summary":"Exploiting Redundancy in Pre-trained Models for Efficient Transfer Learning, Machine Learning and Data Analytics Symposium, Qatar (Mar. 2021) Exploiting Redundancy in Pre-trained Models for Efficient Transfer Learning, Facebook, US (Feb 2021) Exploiting Redundancy in Pre-trained Models for Efficient Transfer Learning, National Research Council, Canada (Nov 2020) Interpreting Deep NLP Models, University of Edinburgh, UK (April 2020) Summarizing Research on Interpreting Machine Translation Models, University of Sheffield, UK (Mar 2020) Efficient Transfer Learning of Pretrained Model, 7th International Conference on Language and Technology, Pakistan (February 2020) Analyzing Individual Neurons in Deep NLP Models at Google, Facebook, Amazon, Salesforce and Bosch, US (April 2019) Hidden Linguistics in Deep NLP Models, Symposium on Natural Language Processing, University of Moratuwa, Sri Lanka (March 2019) Machine Translation in the Real World, Kings College London, UK (March 2019) Analyzing Individual Neurons in Deep NLP Models, University of Melbourne, Melbourne, Australia (Feb.","tags":null,"title":"Talks","type":"pages"},{"authors":null,"categories":null,"content":"   Deep Learning for Natural Language Processing A 15 hours crash course covering the basics and advancements in deep learning. The lecture series is conducted at the department of Computer Science and Applied Cognitive Science of the University of Duisburg-Essen.\nIntroduction to Deep Learning for Natural Language Processing A one week introductory course delivered at the DAAD organized Spring School, University of Moratuwa, Sri Lanka in March 2019.\nFrom Theory to Practice: Deep Learning for Natural Language Processing A 15 hours crash course on deep learning for NLP with practical exercises in Keras. The lecture series is conducted at the department of Computer Science and Applied Cognitive Science of the University of Duisburg-Essen. Here is the course material including slides, python notebooks, etc. link\nDeep Learning for Machine Translation I with Fahim Dalvi delivered a 15 hours intensive course on deep learning for machine translation in September 2017 at DGfS-CL Fall School in Heinrich Heine Universität Düsseldorf. We covered neural networks, language models, recurrent neural network and how they fit in to become a neural machine translation. link\n","date":1593302400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593302400,"objectID":"64bea613779af496ad54fa2f696cf5be","permalink":"//localhost:54935/pages/teaching/","publishdate":"2020-06-28T00:00:00Z","relpermalink":"/pages/teaching/","section":"pages","summary":"Deep Learning for Natural Language Processing A 15 hours crash course covering the basics and advancements in deep learning. The lecture series is conducted at the department of Computer Science and Applied Cognitive Science of the University of Duisburg-Essen.\nIntroduction to Deep Learning for Natural Language Processing A one week introductory course delivered at the DAAD organized Spring School, University of Moratuwa, Sri Lanka in March 2019.","tags":null,"title":"Teaching","type":"pages"},{"authors":["Fahim Dalvi","Hassan Sajjad","Nadir Durrani","Yonatan Belinkov"],"categories":null,"content":"","date":1585688400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585688400,"objectID":"08aae5bced2b0e0f8a3e739989f18883","permalink":"//localhost:54935/publication/dalvi-featureselection-arxiv/","publishdate":"2020-04-01T00:00:00+03:00","relpermalink":"/publication/dalvi-featureselection-arxiv/","section":"publication","summary":"","tags":null,"title":"Exploiting Redundancy in Pre-trained Language Models for Efficient Transfer Learning","type":"publication"},{"authors":["Abdul Rafae","Asim Karim","Hassan Sajjad","Faisal Kamiran","Jia Xu"],"categories":null,"content":"","date":1583010000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583010000,"objectID":"8f1054158d18276d574f8d887e39a414","permalink":"//localhost:54935/publication/rafae-2018-cl/","publishdate":"2020-03-01T00:00:00+03:00","relpermalink":"/publication/rafae-2018-cl/","section":"publication","summary":"","tags":["journal"],"title":"A Clustering Framework for Lexical Normalization of Roman Urdu","type":"publication"},{"authors":["Prakhar Ganesh","Yao Chen","Xin Lou","Mohammad Haris Ali Khan","Yin Yang","Deming Chen","Marianne Winslett","Hassan Sajjad","Preslav Nakov"],"categories":null,"content":"","date":1577826000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577826000,"objectID":"5e7b7dc51823d2d0942c39f9ad9ce73b","permalink":"//localhost:54935/publication/ganeshcompressingbert-arxiv/","publishdate":"2020-01-01T00:00:00+03:00","relpermalink":"/publication/ganeshcompressingbert-arxiv/","section":"publication","summary":"","tags":null,"title":"Compressing Large-Scale Transformer-Based Models: A Case Study on BERT","type":"publication"},{"authors":["Yonatan Belinkov","Nadir Durrani","Hassan Sajjad","Fahim Dalvi","James Glass"],"categories":null,"content":"","date":1577826000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577826000,"objectID":"405502fc12e4057fb7318a63327b0e8f","permalink":"//localhost:54935/publication/belinkov-2020-cl/","publishdate":"2020-01-01T00:00:00+03:00","relpermalink":"/publication/belinkov-2020-cl/","section":"publication","summary":"","tags":null,"title":"On the Linguistic Representational Power of Neural Machine Translation Models","type":"publication"},{"authors":["Hassan Sajjad","Fahim Dalvi","Nadir Durrani","Preslav Nakov"],"categories":null,"content":"","date":1577826000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577826000,"objectID":"4bc764d9ffe040d5f20d528ecb7b4fa2","permalink":"//localhost:54935/publication/sajjad-poormanbert-arxiv/","publishdate":"2020-01-01T00:00:00+03:00","relpermalink":"/publication/sajjad-poormanbert-arxiv/","section":"publication","summary":"","tags":null,"title":"Poor Man's BERT: Smaller and Faster Transformer Models","type":"publication"},{"authors":["Hamdy Mubarak","Ahmed Abdelali","Kareem Darwish","Mohamed Eldesouki","Younes Samih","Hassan Sajjad"],"categories":null,"content":"","date":1572555600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572555600,"objectID":"8bc7f837d04ce5635c6c6b8e98d034ef","permalink":"//localhost:54935/publication/diacritic-2019-emnlp/","publishdate":"2019-11-01T00:00:00+03:00","relpermalink":"/publication/diacritic-2019-emnlp/","section":"publication","summary":"","tags":null,"title":"A System for Diacritizing Four Varieties of Arabic","type":"publication"},{"authors":["Paul Michel, Antonios Anastasopoulos, Yonatan Belinkov, Nadir Durrani, Orhan Firat, Philipp Koehn, Graham Neubig, Juan Pino, Xian Li","Hassan Sajjad"],"categories":null,"content":"","date":1564606800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564606800,"objectID":"0fe167d92df1aff442b89bacfd673241","permalink":"//localhost:54935/publication/mtrobustness-2019/","publishdate":"2019-08-01T00:00:00+03:00","relpermalink":"/publication/mtrobustness-2019/","section":"publication","summary":"","tags":null,"title":"Findings of the WMT 2019 Shared Task on Machine Translation Robustness.","type":"publication"},{"authors":["Hamdy Mubarak","Ahmed Abdelali","Hassan Sajjad","Younes Samih","Kareem Darwish"],"categories":null,"content":"","date":1559336400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559336400,"objectID":"5a4d1a099c3312b5324752eb66f302c4","permalink":"//localhost:54935/publication/mubarak-2019-naacl/","publishdate":"2019-06-01T00:00:00+03:00","relpermalink":"/publication/mubarak-2019-naacl/","section":"publication","summary":"","tags":null,"title":"Highly Effective Arabic Diacritization using Sequence to Sequence Modeling","type":"publication"},{"authors":["Nadir Durrani","Fahim Dalvi","Hassan Sajjad","Yonatan Belinkov","Preslav Nakov"],"categories":null,"content":"","date":1559336400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559336400,"objectID":"097e7fd74ec3d6b97302d9480202ea42","permalink":"//localhost:54935/publication/durrani-2019-naacl/","publishdate":"2019-06-01T00:00:00+03:00","relpermalink":"/publication/durrani-2019-naacl/","section":"publication","summary":"","tags":null,"title":"One Size Does Not Fit All: Comparing NMT Representations of Different Granularities","type":"publication"},{"authors":["D. Anthony Bau*","Yonatan Belinkov*","Hassan Sajjad","Fahim Dalvi","Nadir Durrani","James Glass"],"categories":null,"content":"","date":1556658000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556658000,"objectID":"de9e0ff3a45b4c9ecce1a486f96e8e16","permalink":"//localhost:54935/publication/individual-iclr-19/","publishdate":"2019-05-01T00:00:00+03:00","relpermalink":"/publication/individual-iclr-19/","section":"publication","summary":"","tags":["conference"],"title":"Identifying and Controlling Important Neurons in Neural Machine Translation","type":"publication"},{"authors":["Fahim Dalvi*","Nadir Durrani*","Hassan Sajjad*","Yonatan Belinkov","D. Anthony Bau","James Glass"],"categories":null,"content":"","date":1551387600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551387600,"objectID":"4b0d23f5a88d160f999369324c09f064","permalink":"//localhost:54935/publication/grain-aaai-19-1/","publishdate":"2019-03-01T00:00:00+03:00","relpermalink":"/publication/grain-aaai-19-1/","section":"publication","summary":"","tags":["conference"],"title":"What is one Grain of Sand in the Desert? Analyzing Individual Neurons in Deep NLP Models","type":"publication"},{"authors":["Fahim Dalvi","Avery Nortonsmith","D. Anthony Bau","Yonatan Belinkov","Hassan Sajjad","Nadir Durrani","James Glass"],"categories":null,"content":"","date":1546290000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546290000,"objectID":"74f59e2589219dfc13e8292a8c6dd81b","permalink":"//localhost:54935/publication/neurox-aaai-19-demo/","publishdate":"2019-01-01T00:00:00+03:00","relpermalink":"/publication/neurox-aaai-19-demo/","section":"publication","summary":"","tags":null,"title":"NeuroX: A Toolkit for Analyzing Individual Neurons in Neural Networks","type":"publication"},{"authors":["Fahim Dalvi","Nadir Durrani","Hassan Sajjad","Stephan Vogel"],"categories":null,"content":"","date":1527800400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527800400,"objectID":"f40613fd37eedac037a2db2ca81a15b1","permalink":"//localhost:54935/publication/dalvi-2018-naacl/","publishdate":"2018-06-01T00:00:00+03:00","relpermalink":"/publication/dalvi-2018-naacl/","section":"publication","summary":"","tags":null,"title":"Incremental Decoding and Training Methods for Simultaneous Translation in Neural Machine Translation","type":"publication"},{"authors":["Houda Bouamor","Hassan Sajjad"],"categories":null,"content":"","date":1525122000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525122000,"objectID":"3282fa3dd5b536b269fd1cc7da565421","permalink":"//localhost:54935/publication/bouamor-bucc-18/","publishdate":"2018-05-01T00:00:00+03:00","relpermalink":"/publication/bouamor-bucc-18/","section":"publication","summary":"","tags":null,"title":"H2@BUCC18: Parallel Sentence Extraction from Comparable Corpora Using Multilingual Sentence Embeddings","type":"publication"},{"authors":["Hassan Sajjad","Nadir Durrani","Fahim Dalvi","Yonatan Belinkov","Stephan Vogel"],"categories":null,"content":"","date":1512075600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512075600,"objectID":"0549c4455cd0de7d24aa8431765ce4df","permalink":"//localhost:54935/publication/sajjad-etal-iwslt-17/","publishdate":"2017-12-01T00:00:00+03:00","relpermalink":"/publication/sajjad-etal-iwslt-17/","section":"publication","summary":"","tags":null,"title":"Neural Machine Translation Training in a Multi-Domain Scenario","type":"publication"},{"authors":["Yonatan Belinkov","Lluís Màrquez","Hassan Sajjad","Nadir Durrani","Fahim Dalvi","James Glass"],"categories":null,"content":"","date":1509483600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1509483600,"objectID":"1824046d42e4d3bae9ff62d37e7d7354","permalink":"//localhost:54935/publication/belinkov-ijcnlp-2017/","publishdate":"2017-11-01T00:00:00+03:00","relpermalink":"/publication/belinkov-ijcnlp-2017/","section":"publication","summary":"","tags":null,"title":"Evaluating Layers of Representation in Neural Machine Translation on Part-of-Speech and Semantic Tagging Tasks","type":"publication"},{"authors":["Fahim Dalvi","Nadir Durrani","Hassan Sajjad","Yonatan Belinkov","Stephan Vogel"],"categories":null,"content":"","date":1509483600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1509483600,"objectID":"b63a10ec232fb9e9bba894e43769f3ed","permalink":"//localhost:54935/publication/dalvi-ijcnlp-2017/","publishdate":"2017-11-01T00:00:00+03:00","relpermalink":"/publication/dalvi-ijcnlp-2017/","section":"publication","summary":"","tags":null,"title":"Understanding and Improving Morphological Learning in the Neural Machine Translation Decoder","type":"publication"},{"authors":["Hassan Sajjad","Fahim Dalvi","Nadir Durrani","Ahmed Abdelali","Yonatan Belinkov","Stephan Vogel"],"categories":null,"content":"","date":1501534800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501534800,"objectID":"d7b5adef990b11556c57ffcc4fd08716","permalink":"//localhost:54935/publication/sajjad-etal-2017-acl-short/","publishdate":"2017-08-01T00:00:00+03:00","relpermalink":"/publication/sajjad-etal-2017-acl-short/","section":"publication","summary":"","tags":null,"title":"Challenging Language-Dependent Segmentation for Arabic: An Application to Machine Translation and Part-of-Speech Tagging","type":"publication"},{"authors":["Yonatan Belinkov","Nadir Durrani","Fahim Dalvi","Hassan Sajjad","James Glass"],"categories":null,"content":"","date":1501534800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501534800,"objectID":"0ccfb74a01fab043685711a6b3140360","permalink":"//localhost:54935/publication/belinkov-2017-acl/","publishdate":"2017-08-01T00:00:00+03:00","relpermalink":"/publication/belinkov-2017-acl/","section":"publication","summary":"","tags":null,"title":"What do Neural Machine Translation Models Learn about Morphology?","type":"publication"},{"authors":["Dat Tien Nguyen","Kamla Al-Mannai","Shafiq Joty","Hassan Sajjad","Muhammad Imran","Prasenjit Mitra"],"categories":null,"content":"","date":1493586000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493586000,"objectID":"1e375de38a72f3a8da479bcf35487f71","permalink":"//localhost:54935/publication/nguyen-icwsm-2017/","publishdate":"2017-05-01T00:00:00+03:00","relpermalink":"/publication/nguyen-icwsm-2017/","section":"publication","summary":"","tags":null,"title":"Robust Classification of Crisis-Related Data on Social Networks using Convolutional Neural Networks","type":"publication"},{"authors":["Fahim Dalvi","Yifan Zhang","Sameer Khurana","Nadir Durrani","Hassan Sajjad","Ahmed Abdelali","Hamdy Mubarak","Ahmed Ali","Stephan Vogel"],"categories":null,"content":"","date":1490994000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1490994000,"objectID":"cf074ee6cce6fd2541d4c80f5bb859c9","permalink":"//localhost:54935/publication/dalvi-2017-qcri/","publishdate":"2017-04-01T00:00:00+03:00","relpermalink":"/publication/dalvi-2017-qcri/","section":"publication","summary":"","tags":null,"title":"QCRI Live Speech Translation System","type":"publication"},{"authors":["Renars Liepins","Ulrich Germann","Guntis Barzdins","Alexandra Birch","Steve Renals","Susanne Weberu","Peggy van der Kreefti","Hervé Bourlard","João PrietoJ","Ondrej Klejch"," others"],"categories":null,"content":"","date":1490994000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1490994000,"objectID":"694f7382cd39a3b866644fd22db6a893","permalink":"//localhost:54935/publication/liepins-2017-summa/","publishdate":"2017-04-01T00:00:00+03:00","relpermalink":"/publication/liepins-2017-summa/","section":"publication","summary":"","tags":null,"title":"The SUMMA Platform Prototype","type":"publication"},{"authors":["Shafiq Joty","Nadir Durrani","Hassan Sajjad","Ahmed Abdelali"],"categories":null,"content":"","date":1483218000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483218000,"objectID":"022a43549e85b4374b972b144fd48ff0","permalink":"//localhost:54935/publication/joty-2017-csl/","publishdate":"2017-01-01T00:00:00+03:00","relpermalink":"/publication/joty-2017-csl/","section":"publication","summary":"","tags":null,"title":"Domain Adaptation using Neural Network Joint Model","type":"publication"},{"authors":["Hassan Sajjad","Helmut Schmid","Alexander Fraser","Hinrich Schütze"],"categories":null,"content":"","date":1483218000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483218000,"objectID":"398c8e53eba50552586e66d659069880","permalink":"//localhost:54935/publication/sajjad-2017-statistical/","publishdate":"2017-01-01T00:00:00+03:00","relpermalink":"/publication/sajjad-2017-statistical/","section":"publication","summary":"","tags":null,"title":"Statistical models for unsupervised, semi-supervised and supervised transliteration mining","type":"publication"},{"authors":["Nadir Durrani","Hassan Sajjad","Shafiq Joty","Ahmed Abdelali"],"categories":null,"content":"","date":1480539600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480539600,"objectID":"be9b6fcfa5fd626f02b0676c586ffcf0","permalink":"//localhost:54935/publication/durrani-et-al-2016-coling/","publishdate":"2016-12-01T00:00:00+03:00","relpermalink":"/publication/durrani-et-al-2016-coling/","section":"publication","summary":"","tags":null,"title":"A Deep Fusion Model for Domain Adaptation in Phrase-based MT","type":"publication"},{"authors":["Mohamed Eldesouki","Fahim Dalvi","Hassan Sajjad","Kareem Darwish"],"categories":null,"content":"","date":1480539600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480539600,"objectID":"5a19026b521c2f3708bab6a5d24e8844","permalink":"//localhost:54935/publication/eldesouki-2016-qcri/","publishdate":"2016-12-01T00:00:00+03:00","relpermalink":"/publication/eldesouki-2016-qcri/","section":"publication","summary":"","tags":null,"title":"QCRI @ DSL 2016: Spoken Arabic Dialect Identification Using Textual","type":"publication"},{"authors":["Nadir Durrani","Fahim Dalvi","Hassan Sajjad","Stephan Vogel"],"categories":null,"content":"","date":1480539600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480539600,"objectID":"246f8f95eb8d5911b4d5ccf08df6de3b","permalink":"//localhost:54935/publication/durrani-etal-iwslt-16/","publishdate":"2016-12-01T00:00:00+03:00","relpermalink":"/publication/durrani-etal-iwslt-16/","section":"publication","summary":"","tags":null,"title":"QCRI’s Machine Translation Systems for IWSLT’2016","type":"publication"},{"authors":["Hassan Sajjad","Francisco Guzmán","Stephan Vogel"],"categories":null,"content":"","date":1475269200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475269200,"objectID":"887b748667f4f2d93f8efa31663ae4a3","permalink":"//localhost:54935/publication/sajjad-16-postediting/","publishdate":"2016-10-01T00:00:00+03:00","relpermalink":"/publication/sajjad-16-postediting/","section":"publication","summary":"","tags":null,"title":"An Empirical Study: Post-editing Effort for English to Arabic Hybrid Machine Translation","type":"publication"},{"authors":["Dat Tien Nguyen","Shafiq Joty","Muhammad Imran","Hassan Sajjad","Prasenjit Mitra"],"categories":null,"content":"","date":1475269200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475269200,"objectID":"96388768b7dcd1674ffa9df92977177b","permalink":"//localhost:54935/publication/nguyen-2016-swdm/","publishdate":"2016-10-01T00:00:00+03:00","relpermalink":"/publication/nguyen-2016-swdm/","section":"publication","summary":"","tags":null,"title":"Applications of Online Deep Learning for Crisis Response Using Social Media Information","type":"publication"},{"authors":["Wajdi Zaghouani","Ahmed Abdelali","Francisco Guzmán","Hassan Sajjad"],"categories":null,"content":"","date":1475269200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475269200,"objectID":"957d393119b0ca8d0525167939acf5d3","permalink":"//localhost:54935/publication/zaghouani-2016-normalizing/","publishdate":"2016-10-01T00:00:00+03:00","relpermalink":"/publication/zaghouani-2016-normalizing/","section":"publication","summary":"","tags":null,"title":"Normalizing Mathematical Expressions to Improve the Translation of Educational Content","type":"publication"},{"authors":["Hassan Sajjad","Francisco Guzmán","Nadir Durrani","Ahmed Abdelali","Houda Bouamor","Irina P Temnikova","Stephan Vogel"],"categories":null,"content":"","date":1464728400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1464728400,"objectID":"8ea4e00ad76ab5a2c5b601da7f30ea66","permalink":"//localhost:54935/publication/sajjad-2016-eyes/","publishdate":"2016-06-01T00:00:00+03:00","relpermalink":"/publication/sajjad-2016-eyes/","section":"publication","summary":"","tags":null,"title":"Eyes Don't Lie: Predicting Machine Translation Quality Using Eye Movement.","type":"publication"},{"authors":["Nadir Durrani","Hassan Sajjad","Shafiq, Joty","Ahmed Abdelali","Stephan Vogel"],"categories":null,"content":"","date":1446325200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1446325200,"objectID":"c3033690c577e751840eefbc9ec44ebe","permalink":"//localhost:54935/publication/durrani-et-al-mt-summit-2015/","publishdate":"2015-11-01T00:00:00+03:00","relpermalink":"/publication/durrani-et-al-mt-summit-2015/","section":"publication","summary":"","tags":null,"title":"Using Joint Models for Domain Adaptation in Statistical Machine Translation","type":"publication"},{"authors":["Abdul Rafae","Abdul Qayyum","Muhammad Moeen Uddin","Asim Karim","Hassan Sajjad","Faisal Kamiran"],"categories":null,"content":"","date":1441054800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441054800,"objectID":"ef69c37addc838d8e9c5304bc6678d48","permalink":"//localhost:54935/publication/rafae-2015-unsupervised/","publishdate":"2015-09-01T00:00:00+03:00","relpermalink":"/publication/rafae-2015-unsupervised/","section":"publication","summary":"","tags":null,"title":"An Unsupervised Method for Discovering Lexical Variations in Roman Urdu Informal Text.","type":"publication"},{"authors":["Francisco Guzmán","Ahmed Abdelali","Irina Temnikova","Hassan Sajjad","Stephan Vogel"],"categories":null,"content":"","date":1441054800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441054800,"objectID":"6be35840a0d61b0391c05c25507f9f5f","permalink":"//localhost:54935/publication/guzman-wmt-15/","publishdate":"2015-09-01T00:00:00+03:00","relpermalink":"/publication/guzman-wmt-15/","section":"publication","summary":"","tags":null,"title":"How do Humans Evaluate Machine Translation","type":"publication"},{"authors":["Shafiq Joty","Hassan Sajjad","Nadir Durrani","Kamla Al-Mannai","Ahmed Abdelali","Stephan Vogel"],"categories":null,"content":"","date":1441054800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441054800,"objectID":"574f338530633256d6804a16f4f7eed4","permalink":"//localhost:54935/publication/joty-et-al-2015-emnlp/","publishdate":"2015-09-01T00:00:00+03:00","relpermalink":"/publication/joty-et-al-2015-emnlp/","section":"publication","summary":"","tags":null,"title":"How to Avoid Unwanted Pregnancies: Domain Adaptation using Neural Network Models","type":"publication"},{"authors":["Houda Bouamor","Hassan Sajjad","Nadir Durrani","Kemal Oflazer"],"categories":null,"content":"","date":1435698000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435698000,"objectID":"8de682234450787dbe4b6762c337a15e","permalink":"//localhost:54935/publication/bouamor-anlp-15/","publishdate":"2015-07-01T00:00:00+03:00","relpermalink":"/publication/bouamor-anlp-15/","section":"publication","summary":"","tags":null,"title":"QCMUQ@QALB-2015 Shared Task: Combining Character level MT and Error-tolerant Finite-State Recognition for ArabicSpelling Correction","type":"publication"},{"authors":["Hassan Sajjad","Nadir Durrani","Francisco Guzman","Preslav Nakov","Ahmed Abdelali","Stephan Vogel","Wael Salloum","Ahmed El Kholy","Nizar Habash"],"categories":null,"content":"","date":1433106000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1433106000,"objectID":"50518e96cb3dec5f6fd931df0ac1ce30","permalink":"//localhost:54935/publication/sajjad-nist-15/","publishdate":"2015-06-01T00:00:00+03:00","relpermalink":"/publication/sajjad-nist-15/","section":"publication","summary":"","tags":null,"title":"QCN Egyptian Arabic to English MachineTranslation System for NIST OpenMT15","type":"publication"},{"authors":["Walid Magdy","Hassan Sajjad","Tarek El-Ganainy","Fabrizio Sebastiani"],"categories":null,"content":"","date":1430427600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1430427600,"objectID":"05ff2ae3269bfe996c70b4d08a466b28","permalink":"//localhost:54935/publication/magdy-2015-distant/","publishdate":"2015-05-01T00:00:00+03:00","relpermalink":"/publication/magdy-2015-distant/","section":"publication","summary":"","tags":null,"title":"Distant Supervision for Tweet Classification Using YouTube Labels","type":"publication"},{"authors":["Walid Magdy","Hassan Sajjad","Tarek El-Ganainy","Fabrizio Sebastiani"],"categories":null,"content":"","date":1420059600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420059600,"objectID":"419ee0168cce707b3f8cc9ba78d461c3","permalink":"//localhost:54935/publication/madgy-2015-snam/","publishdate":"2015-01-01T00:00:00+03:00","relpermalink":"/publication/madgy-2015-snam/","section":"publication","summary":"","tags":null,"title":"Bridging social media via distant supervision","type":"publication"},{"authors":["Kamla Al-Mannai","Hassan Sajjad","Alaa Khader","Fahad Al Obaidli","Preslav Nakov","Stephan Vogel"],"categories":null,"content":"","date":1412110800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1412110800,"objectID":"f2a9e4fd906f9e348b712a7780873c1a","permalink":"//localhost:54935/publication/kamla-anlp-2014/","publishdate":"2014-10-01T00:00:00+03:00","relpermalink":"/publication/kamla-anlp-2014/","section":"publication","summary":"","tags":null,"title":"Unsupervised word segmentation improves dialectal Arabic to English machine translation","type":"publication"},{"authors":["Kareem Darwish","Hassan Sajjad","Hamdy Mubarak"],"categories":null,"content":"","date":1412110800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1412110800,"objectID":"a7c47d79f6e09936fdbee51fd0b718af","permalink":"//localhost:54935/publication/darwish-2014-verifiably/","publishdate":"2014-10-01T00:00:00+03:00","relpermalink":"/publication/darwish-2014-verifiably/","section":"publication","summary":"","tags":null,"title":"Verifiably Effective Arabic Dialect Identification.","type":"publication"},{"authors":["Ahmed Abdelali","Francisco Guzman","Hassan Sajjad","Stephan Vogel"],"categories":null,"content":"","date":1398891600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1398891600,"objectID":"3c3c95a630d879df580c47351aaccdc0","permalink":"//localhost:54935/publication/abdelali-2014-lrec/","publishdate":"2014-05-01T00:00:00+03:00","relpermalink":"/publication/abdelali-2014-lrec/","section":"publication","summary":"","tags":null,"title":"The AMARA Corpus: Building Parallel Language Resources for the Educational Domain","type":"publication"},{"authors":["Mohammad Moeen Uddin","Mohammad Imran","Hassan Sajjad"],"categories":null,"content":"","date":1398891600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1398891600,"objectID":"c6c48d737a8eb56d2958b067be4c6f3d","permalink":"//localhost:54935/publication/uddin-socialcom-2014/","publishdate":"2014-05-01T00:00:00+03:00","relpermalink":"/publication/uddin-socialcom-2014/","section":"publication","summary":"","tags":null,"title":"Understanding Types of Users on Twitter","type":"publication"},{"authors":["Nadir Durrani","Hassan Sajjad","Hieu Hoang","Philipp Koehn"],"categories":null,"content":"","date":1396299600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1396299600,"objectID":"16c4de70a4ca7b402535b3fabbc3b917","permalink":"//localhost:54935/publication/durrani-et-al-2014-eacl/","publishdate":"2014-04-01T00:00:00+03:00","relpermalink":"/publication/durrani-et-al-2014-eacl/","section":"publication","summary":"","tags":null,"title":"Integrating an Unsupervised Transliteration Model into Statistical Machine Translation","type":"publication"},{"authors":["Hassan Sajjad","Francisco Guzmán","Preslav Nakov","Ahmed Abdelali","Kenton Murray","Fahad Al Obaidli","Stephan Vogel"],"categories":null,"content":"","date":1385845200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1385845200,"objectID":"875d5162ede9065db51772c07569b64f","permalink":"//localhost:54935/publication/sajjad-etal-iwslt-13/","publishdate":"2013-12-01T00:00:00+03:00","relpermalink":"/publication/sajjad-etal-iwslt-13/","section":"publication","summary":"","tags":null,"title":"QCRI at IWSLT 2013: Experiments in Arabic-English and English-Arabic Spoken Language Translation","type":"publication"},{"authors":["Francisco Guzmán","Hassan Sajjad","Stephan Vogel","Ahmed Abdelali"],"categories":null,"content":"","date":1385845200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1385845200,"objectID":"b8747c2c6a2afc9aeffcd2033e729d9b","permalink":"//localhost:54935/publication/guzman-sajjad-etal-iwslt-13/","publishdate":"2013-12-01T00:00:00+03:00","relpermalink":"/publication/guzman-sajjad-etal-iwslt-13/","section":"publication","summary":"","tags":null,"title":"The AMARA Corpus: Building Resources for Translating the Web's Educational Content","type":"publication"},{"authors":["Marion Weller","Max Kisselew","Svetlana Smekalova","Alexander Fraser","Helmut Schmid","Nadir Durrani","Hassan Sajjad","Richárd Farkas"],"categories":null,"content":"","date":1375304400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1375304400,"objectID":"b2a0b44a710cc0cb000b0bf77d9fc3dd","permalink":"//localhost:54935/publication/weller-13-wmt-13/","publishdate":"2013-08-01T00:00:00+03:00","relpermalink":"/publication/weller-13-wmt-13/","section":"publication","summary":"","tags":null,"title":"Munich-Edinburgh-Stuttgart Submissions at WMT13: Morphological and Syntactic Processing for SMT","type":"publication"},{"authors":["Nadir Durrani","Helmut Schmid","Alexander Fraser","Hassan Sajjad","Richárd Farkas"],"categories":null,"content":"","date":1375304400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1375304400,"objectID":"deefd41c495c249f029697a02bbfa724","permalink":"//localhost:54935/publication/durrani-et-al-2013-wmt/","publishdate":"2013-08-01T00:00:00+03:00","relpermalink":"/publication/durrani-et-al-2013-wmt/","section":"publication","summary":"","tags":null,"title":"Munich-Edinburgh-Stuttgart Submissions of OSM Systems at WMT13","type":"publication"},{"authors":["Hassan Sajjad","Svetlana Smekalova","Nadir Durrani","Alexander Fraser","Helmut Schmid"],"categories":null,"content":"","date":1375304400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1375304400,"objectID":"3a28ac43e5d077c39cca90fe976eddaf","permalink":"//localhost:54935/publication/sajjad-et-al-2013-wmt/","publishdate":"2013-08-01T00:00:00+03:00","relpermalink":"/publication/sajjad-et-al-2013-wmt/","section":"publication","summary":"","tags":null,"title":"QCRI-MES Submission at WMT13: Using Transliteration Mining to Improve Statistical Machine Translation","type":"publication"},{"authors":["Hassan Sajjad","Kareem Darwish","Yonatan Belinkov"],"categories":null,"content":"","date":1375304400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1375304400,"objectID":"0af64e2b78f89a0b7538fa7c63f14814","permalink":"//localhost:54935/publication/sajjad-2013-translating/","publishdate":"2013-08-01T00:00:00+03:00","relpermalink":"/publication/sajjad-2013-translating/","section":"publication","summary":"","tags":null,"title":"Translating Dialectal Arabic to English","type":"publication"},{"authors":["Hassan Sajjad","Patrick Pantel","Michael Gamon"],"categories":null,"content":"","date":1354309200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1354309200,"objectID":"6868f8be1006e552a72ccaeac62a766a","permalink":"//localhost:54935/publication/sajjad-coling-2012/","publishdate":"2012-12-01T00:00:00+03:00","relpermalink":"/publication/sajjad-coling-2012/","section":"publication","summary":"","tags":null,"title":"Underspecified Query Refinement via Natural Language Question Generation","type":"publication"},{"authors":["Hassan Sajjad","Alexander Fraser","Helmut Schmid"],"categories":null,"content":"","date":1341090000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1341090000,"objectID":"58b7ef68e9e4571e1b89ce8f8f031a6d","permalink":"//localhost:54935/publication/sajjad-acl-12/","publishdate":"2012-07-01T00:00:00+03:00","relpermalink":"/publication/sajjad-acl-12/","section":"publication","summary":"","tags":null,"title":"A Statistical Model for Unsupervised and Semi-supervised Transliteration Mining","type":"publication"},{"authors":["Hassan Sajjad","Nadir Durrani","Helmut Schmid","Alexander Fraser"],"categories":null,"content":"","date":1320094800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1320094800,"objectID":"84a6d13f1b90099881ed6fd5cc46c7b7","permalink":"//localhost:54935/publication/sajjad-et-al-2011-ijcnlp-2011/","publishdate":"2011-11-01T00:00:00+03:00","relpermalink":"/publication/sajjad-et-al-2011-ijcnlp-2011/","section":"publication","summary":"","tags":null,"title":"Comparing Two Techniques for Learning Transliteration Models Using a Parallel Corpus","type":"publication"},{"authors":["Hassan Sajjad","Alexander Fraser","Helmut Schmid"],"categories":null,"content":"","date":1306875600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1306875600,"objectID":"f39bc754068ddc73b636891dc795fb7b","permalink":"//localhost:54935/publication/sajjad-acl-11/","publishdate":"2011-06-01T00:00:00+03:00","relpermalink":"/publication/sajjad-acl-11/","section":"publication","summary":"","tags":null,"title":"An Algorithm for Unsupervised Transliteration Mining with an Application to Word Alignment","type":"publication"},{"authors":["Nadir Durrani","Hassan Sajjad","Alexander Fraser","Helmut Schmid"],"categories":null,"content":"","date":1277931600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1277931600,"objectID":"466ed24aa198bddba7f8da650e81da52","permalink":"//localhost:54935/publication/durrani-et-al-2010-acl/","publishdate":"2010-07-01T00:00:00+03:00","relpermalink":"/publication/durrani-et-al-2010-acl/","section":"publication","summary":"","tags":null,"title":"Hindi-to-Urdu Machine Translation through Transliteration","type":"publication"},{"authors":["Hassan Sajjad","Helmut Schmid"],"categories":null,"content":"","date":1238533200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1238533200,"objectID":"997607e8177520db0b5be91102d4b5da","permalink":"//localhost:54935/publication/sajjad-eacl-09/","publishdate":"2009-04-01T00:00:00+03:00","relpermalink":"/publication/sajjad-eacl-09/","section":"publication","summary":"","tags":null,"title":"Tagging Urdu Text with Parts of Speech: A Tagger Comparison","type":"publication"}]